name: EKS Deploy

on:
  repository_dispatch:
    types: [iam-roles-updated]
  pull_request:
    branches:
      - '*'
  push:
    branches:
      - main

env:
    AWS_REGION: us-west-2

permissions:
  id-token: write   # This is required for requesting the JWT
  contents: read    # This is required for actions/checkout

jobs:
  create_eks_cluster:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Parse Dispatch Data
        if: github.event_name == 'repository_dispatch'
        run: |
          echo "EKS_NODE_GROUP_ROLE_ARN=${{ github.event.client_payload.eks_node_group_role_arn }}" >> $GITHUB_ENV
          echo "GITHUB_ACTIONS_ROLE_ARN=${{ github.event.client_payload.github_actions_role_arn }}" >> $GITHUB_ENV

      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ env.GITHUB_ACTIONS_ROLE_ARN }}
          aws-region: ${{ env.AWS_REGION }}
          role-session-name: github-actions

      - name: Set up Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: 1.8.1

      - name: Terraform Init
        run: terraform init
        working-directory: ./terraform/eks

      - name: Terraform Plan
        if: github.event_name == 'pull_request'
        id: plan
        run: terraform plan -no-color > eks-plan-output.txt
        working-directory: ./terraform/eks

      - name: Post Plan Comment
        if: github.event_name == 'pull_request'
        uses: marocchino/sticky-pull-request-comment@v2
        with:
          path: ./terraform/eks/eks-plan-output.txt

      - name: Terraform Apply
        if: (github.event_name == 'push' && github.ref == 'refs/heads/main') || github.event_name == 'repository_dispatch'
        run: terraform apply -auto-approve -var "eks_node_group_role_arn=${{ env.EKS_NODE_GROUP_ROLE_ARN }}"
        working-directory: ./terraform/eks

      - name: Save Outputs
        if: (github.event_name == 'push' && github.ref == 'refs/heads/main') || github.event_name == 'repository_dispatch'
        id: save_outputs
        run: |
          echo "EKS_CLUSTER_NAME=$(terraform output -raw eks_cluster_name)" >> $GITHUB_ENV
        working-directory: ./terraform/eks

  apply_aws_auth_configmap:
    needs: create_eks_cluster
    runs-on: ubuntu-latest
    steps:
      -  name: Checkout code
         uses: actions/checkout@v4

      - name: Parse Dispatch Data
        if: github.event_name == 'repository_dispatch'
        run: |
          echo "GITHUB_ACTIONS_ROLE_ARN=${{ github.event.client_payload.github_actions_role_arn }}" >> $GITHUB_ENV

      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ env.GITHUB_ACTIONS_ROLE_ARN }}
          aws-region: ${{ env.AWS_REGION }}
          role-session-name: github-actions

      - name: Set up kubectl
        run: |
            curl -LO "https://storage.googleapis.com/kubernetes-release/release/$(curl -s https://storage.googleapis.com/kubernetes-release/release/stable.txt)/bin/linux/amd64/kubectl"
            chmod +x ./kubectl
            sudo mv ./kubectl /usr/local/bin/kubectl

      - name: Update kubeconfig
        run: |
            aws eks update-kubeconfig --name my-netflix-eks --region ${{ env.AWS_REGION }}

      - name: Apply aws-auth ConfigMap
        run: |
            cat <<EOF >aws-auth-cm.yaml
            apiVersion: v1
            kind: ConfigMap
            metadata:
              name: aws-auth
              namespace: kube-system
            data:
              mapRoles: |
                - rolearn: ${{ env.EKS_NODE_GROUP_ROLE_ARN }}
                  username: system:node:{{EC2PrivateDNSName}}
                  groups:
                    - system:bootstrappers
                    - system:nodes
                - rolearn: ${{ env.GITHUB_ACTIONS_ROLE_ARN }}
                  username: github-actions-bot-for-k8s # a k8s user the IAM role gets map to
                  groups:
                      - github-actions-group-for-k8s # it's undefined and it is okay as we are going to use the username in below RBAC configuration.
              mapUsers: |
                - userarn: arn:aws:iam::${{ secrets.AWS_ACCOUNT_ID }}:user/administrator
                  username: aws-admin-mapped-for-k8s
                  groups:
                    - system:masters

            EOF
            kubectl apply -f aws-auth-cm.yaml

      - name: Apply RBAC Configuration
        run: |
          cat <<EOF >rbac.yaml
          apiVersion: rbac.authorization.k8s.io/v1
          kind: ClusterRole
          metadata:
            name: github-actions-deployer
          rules:
          - apiGroups: [""]
            resources: ["pods", "services", "endpoints"]
            verbs: ["get", "list", "watch", "create", "delete", "patch", "update"]
          - apiGroups: ["apps"]
            resources: ["deployments", "replicasets"]
            verbs: ["get", "list", "watch", "create", "delete", "patch", "update"]
          - apiGroups: ["batch"]
            resources: ["jobs"]
            verbs: ["get", "list", "watch", "create", "delete", "patch", "update"]
          - apiGroups: ["extensions"]
            resources: ["ingresses"]
            verbs: ["get", "list", "watch", "create", "delete", "patch", "update"]
          ---
          apiVersion: rbac.authorization.k8s.io/v1
          kind: ClusterRoleBinding
          metadata:
            name: github-actions-binding
          subjects:
          - kind: User
            name: github-actions-bot-for-k8s
            apiGroup: rbac.authorization.k8s.io
          roleRef:
            kind: ClusterRole
            name: github-actions-deployer
            apiGroup: rbac.authorization.k8s.io
          EOF
          kubectl apply -f rbac.yaml

      - name: Apply aws-auth ConfigMap
        run: |
            kubectl get pods -o wide
